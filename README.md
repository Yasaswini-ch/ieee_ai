# âš–ï¸ Legal/Policy RAG System (OpenAI + FAISS)

This app ingests **legal/policy documents** (ğŸ“„ PDF, ğŸ“ DOCX, ğŸ“‘ JSONL), chunks them by sections, indexes them with **OpenAI embeddings** into a **FAISS vector store**, and answers user queries **with citations**.  
It also supports **contradiction detection (NLI)**, **explain mode (plain English)**, and **time-machine compliance (compare historical versions)**.

ğŸš€ **Live Demo:** [legalanalyzer.streamlit.app](https://legalanalyzer.streamlit.app/)  

---

## âœ¨ Features
- ğŸ“¥ **Ingestion**: PDF, DOCX, JSONL with metadata (`doc_id`, `section_id`, `version`, `title`, `text`)  
- ğŸ§  **Embeddings**: OpenAI Embeddings (`text-embedding-3-small` by default)  
- ğŸ’¾ **Vector DB**: FAISS (local storage)  
- ğŸ” **RAG**: Retrieve top-K relevant chunks & generate answers via OpenAI GPT  
- ğŸ“Œ **Citations**: Exact references `doc_id/section_id/version`  
- âš”ï¸ **Contradiction Detection**: Optional NLI model to flag contradictions among retrieved chunks  
- ğŸ§’ **Explain Mode**: "Explain like Iâ€™m 5" toggle to simplify language  
- â³ **Time-Machine Compliance**: Query historical versions & diff changes  
- ğŸŒ **Frontend**: Streamlit web app  

---
## Setup
1) Python 3.10+
2) Create a virtual environment (recommended)
3) Install dependencies:
```
pip install -r requirements.txt
```
4) Set your OpenAI API key as an environment variable (do NOT hardcode keys):
- Linux/macOS:
```
export OPENAI_API_KEY="YOUR_KEY_HERE"
```
- Windows PowerShell:
```
$env:OPENAI_API_KEY="YOUR_KEY_HERE"
```

Optionally, copy `.env.example` to `.env` and fill in values, then use a loader like `python-dotenv` (already included) or set environment variables directly.

## Run
```
streamlit run streamlit_app.py
```

## Project Structure
```
legal-rag/
  README.md
  requirements.txt
  .env.example
  streamlit_app.py
  src/
    ingestion.py
    chunking.py
    embedding_store.py
    retrieval.py
    generation.py
    contradictions.py
    versioning.py
    utils.py
  data/
    index/
```

- `data/index/` stores FAISS index files and metadata JSON.
- Upload documents via the Streamlit UI or place files under a directory and point the app to ingest them.

## Notes
- Contradiction detection uses a small NLI model via `transformers`. It is optional and will degrade gracefully if the model cannot be loaded.
- JSONL format expected: one JSON object per line with at least `doc_id`, `version`, `title`, `text`, and optionally `section_id`.
- Use `version` consistently to enable time-machine comparisons.

## Evaluation
- Basic evaluation hooks are included to measure accuracy, citation traceability, and ambiguous query coverage â€” extend `utils.py` as needed.
